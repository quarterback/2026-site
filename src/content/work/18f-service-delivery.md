---

title: "Service Delivery at Scale"
summary: "Design leadership across federal programs serving millions."
systemType: "Eligibility + intake systems"
outcome: 'Patterns adopted across multiple agencies on what "success" meant'
order: 1
featured: true
tags: ["Service Delivery", "Decision Systems", "Federal"]
role: "Design Lead"
timeframe: "Multi-year"
-----------------------

## Snapshot

**Context**
Federal service delivery where policy rules, legacy infrastructure, and operational constraints shape the user experience.

**My role**
Design lead responsible for research synthesis, pattern development, and cross-program alignment.

**What I worked on**
Eligibility, intake, and case-management touchpoints where decisions are made and consequences compound.

**What changed**
Reusable service patterns and decision clarity methods adopted across multiple programs.

---

## The problem

Government services often fail at the moments that matter most: when someone needs help navigating a complex system under time pressure.

The core issue wasn’t just poor interfaces. Eligibility systems, intake processes, and case workflows were designed primarily for compliance and processing volume—not for error recovery, service completion, or the downstream consequences of a “small” design decision.

---

## Constraints

* Multi-program coordination across different technical stacks
* Policy requirements that couldn’t be changed—only interpreted and implemented
* Legacy systems with limited or inconsistent integration points
* Stakeholders measuring success by throughput rather than user outcomes
* High consequence error states (incomplete submissions, ineligibility confusion, avoidable rejection loops)

---

## My role

I led design work that sat between policy intent and delivery reality.

This included:

* synthesizing research signals across programs
* translating failure patterns into shared language teams could act on
* shaping patterns and guidelines that could travel across contexts (not just “fix one screen”)

---

## What I did

### 1) Mapped decision points and failure states

I documented where people most commonly:

* abandoned
* misinterpreted requirements
* submitted incorrect info
* got trapped in loops they couldn’t recover from

The output wasn’t a journey map for show—it was a failure map designed to drive decisions.

### 2) Defined “consequence moments”

I identified moments where UX decisions created downstream harm, including:

* late-stage requirement surprises
* ambiguous eligibility thresholds
* unclear “next step” states after rejection or missing info
* mismatched mental models between policy teams and delivery teams

These became anchor points for prioritization and critique.

### 3) Built a shared vocabulary across teams

I created language that let cross-program teams discuss problems as *service mechanics*, not opinions:

* decision clarity vs. decision opacity
* recoverability vs. dead ends
* compliance success vs. human success
* exception handling as a first-class requirement

This reduced translation overhead between policy, product, engineering, and operations.

### 4) Developed intake patterns that prevented late-stage failure

I created reusable patterns to:

* surface requirements earlier (without overwhelming users)
* structure information collection around decision logic
* reduce “invisible rules” that only appeared at submission time
* make error states legible and recoverable

### 5) Aligned success metrics to service outcomes

I helped teams move beyond “processing volume” as the default KPI by introducing operationally meaningful measures, including:

* completion
* correctness
* avoidable rework
* service recovery time after errors

---

## Key decisions

* **Optimized for recoverability over polish**
  Because high-stakes services don’t fail gracefully by default—and “dead ends” are the real design debt.

* **Surfaced constraints earlier instead of hiding complexity**
  Because late-stage surprises create abandonment, mistrust, and support burden.

* **Designed patterns that travel across programs**
  Because the real impact comes from system-level repeatability, not one-off UI fixes.

---

## Artifacts

* Intake decision flow map (eligibility → verification → submission → recovery)
* “Consequence moments” mapping (where harm is introduced)
* Cross-program pattern library (intake + requirements + error recovery)
* Workshop prompts + critique frameworks for service failure analysis

---

## Outcomes

* Patterns adopted across 4+ federal programs
* Reduced avoidable abandonment during intake and submission
* “Consequence mapping” method reused in training and cross-team critique

---

## What this demonstrates

I can enter complex, politically constrained delivery environments and find leverage points where design decisions create outsized impact.

I don’t need clean slates. I work inside real systems—policy constraints, legacy tools, operational reality—and improve how decisions get made, communicated, and recovered from when they fail.
