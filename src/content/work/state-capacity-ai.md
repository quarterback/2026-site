---
title: "State Capacity AI"
type: "concept"
lede: "Governance frameworks and conceptual primitives for AI-mediated institutions—the foundational work that informs applied decision-layer architecture."
metadata:
  - label: "Timeline"
    value: "2024-Present"
  - label: "Role"
    value: "Founder"
  - label: "Focus"
    value: "Governance primitives & frameworks"
  - label: "Status"
    value: "Ongoing development"
tags: ["AI Governance", "Decision Infrastructure", "Frameworks", "Institutional Design"]
order: 3
featured: true
---

## The Core Problem

AI deployment in public institutions is happening without governance architecture. Organizations are automating high-stakes decisions—eligibility, enforcement, resource allocation—but lack the conceptual frameworks to structure oversight, maintain accountability, or ensure human authority remains on the critical path.

The challenge isn't automation versus human judgment. It's that institutions need decision-layer architecture: frameworks for judgment routing, consequence design, authority delegation, and trust instrumentation that let them operate AI-dependent systems safely and accountably.

## What State Capacity AI Provides

State Capacity AI develops the governance primitives and conceptual frameworks that inform how institutions structure decision-making in AI-mediated environments:

### Judgment Routing Frameworks
How do you determine which decisions get automated, which require human review, and what triggers an override? Judgment routing is the architecture that structures authority delegation—ensuring discretion remains legible and contestable.

### Consequence Design Models
Every automated decision has downstream effects. Consequence design maps impact pathways, identifies failure modes, and establishes the instrumentation needed to make consequences visible before they compound.

### Civil Economics
The economic layer of public services—how resources get allocated, costs get distributed, and value flows through institutional systems. Civil economics frameworks help institutions understand the market dynamics of their AI dependencies.

### Trust Instrumentation
Making automated systems auditable, contestable, and legible to oversight bodies. Trust instrumentation creates the transparency layer that allows institutions to demonstrate accountability for what their systems do.

## How This Connects to Applied Work

State Capacity AI is the conceptual foundation for applied decision-layer infrastructure:

- **Occupant** applies compute intelligence and civil economics frameworks to AI procurement
- **Judgment routing** informs the architecture of automated case management and eligibility systems
- **Consequence design** shapes how organizations map risk in high-stakes decision environments
- **Trust instrumentation** guides the development of audit trails and oversight mechanisms

The frameworks developed here become the primitives that practitioners, technologists, and institutional leaders use to structure governable AI systems.

## Guides, Frameworks & Primitives

State Capacity AI publishes:
- **Decision architecture guides**: How to structure judgment routing, authority delegation, and override mechanisms
- **Governance frameworks**: Templates for oversight bodies, audit protocols, and accountability structures
- **Consequence mapping tools**: Methods for tracing impact pathways and identifying failure modes
- **Procurement primitives**: Evaluation frameworks for AI vendors operating in high-stakes domains

These aren't theoretical—they're operational frameworks used in real institutional contexts where AI is on the critical path.

![Government building representing public institutions](https://images.unsplash.com/photo-1555374018-13a8994ab246?w=1200&h=600&fit=crop)

## Why This Matters

Institutions deploying AI in high-consequence domains need more than tools—they need governance architecture that makes their systems safe to operate. State Capacity AI provides the conceptual infrastructure that lets organizations move from "can we automate this?" to "how do we govern this system responsibly?"

![Data visualization showing complex systems](https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=1200&h=600&fit=crop)

## What This Demonstrates

- **Governance primitive development**: Creating the foundational frameworks that inform institutional AI architecture
- **Conceptual infrastructure**: Building the models and guides that practitioners need to structure accountable systems
- **Decision-layer design**: Establishing how authority, discretion, and oversight get encoded in AI-mediated environments
- **Institutional architecture at scale**: Demonstrating how public organizations can operate confidently in AI-dependent contexts
